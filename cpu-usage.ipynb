{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34805abf-0117-4183-a5c5-d3e62d880b1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T11:42:02.398061Z",
     "iopub.status.busy": "2025-02-27T11:42:02.397062Z",
     "iopub.status.idle": "2025-02-27T11:42:02.402183Z",
     "shell.execute_reply": "2025-02-27T11:42:02.402183Z",
     "shell.execute_reply.started": "2025-02-27T11:42:02.398061Z"
    },
    "id": "34805abf-0117-4183-a5c5-d3e62d880b1f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from data import fetch_dataset\n",
    "from util import move_sliding_window, num_params\n",
    "\n",
    "from model import LSTMModel\n",
    "from algorithm import fedavg,fedkd, fedgkd, cadis\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.set_printoptions(suppress=True, floatmode='fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d3d5845-ec85-4781-9936-c22e6cd99836",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-27T11:42:02.612226Z",
     "iopub.status.busy": "2025-02-27T11:42:02.612226Z",
     "iopub.status.idle": "2025-02-27T11:42:02.629198Z",
     "shell.execute_reply": "2025-02-27T11:42:02.628192Z",
     "shell.execute_reply.started": "2025-02-27T11:42:02.612226Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1713172653750,
     "user": {
      "displayName": "ff ff",
      "userId": "03856258937076952853"
     },
     "user_tz": -120
    },
    "id": "5d3d5845-ec85-4781-9936-c22e6cd99836",
    "outputId": "050236f6-8533-49d7-ef4f-fab50aa3b384",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('running on gpu')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c84b7fb-5aa5-42f3-913c-bab77727e9b7",
   "metadata": {
    "id": "4c84b7fb-5aa5-42f3-913c-bab77727e9b7"
   },
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51a5da4f-168c-4094-928e-de826f846780",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T11:42:04.588758Z",
     "iopub.status.busy": "2025-02-27T11:42:04.587724Z",
     "iopub.status.idle": "2025-02-27T11:42:04.594750Z",
     "shell.execute_reply": "2025-02-27T11:42:04.594750Z",
     "shell.execute_reply.started": "2025-02-27T11:42:04.588758Z"
    },
    "id": "51a5da4f-168c-4094-928e-de826f846780",
    "tags": []
   },
   "outputs": [],
   "source": [
    "window_size = 90 # Define window_size period and split inputs/labels\\\n",
    "batch_size = 1024\n",
    "label_col_index = 0\n",
    "\n",
    "# seq_len = 90  # (timestamps)\n",
    "hidden_dim = 50\n",
    "n_layers = 2\n",
    "lr = 0.0001\n",
    "output_dim = 1\n",
    "\n",
    "#fed train params\n",
    "num_local_epochs = 1\n",
    "max_rounds = 100 #nb of total rounds for training\n",
    "\n",
    "kd_weight = 1\n",
    "buffer_size = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf1ba69-4d95-47a4-84f4-681377656604",
   "metadata": {
    "id": "052833d6-a7f4-4b5f-b387-17f5e0f8cd1f"
   },
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1555d46b-fb60-4ce9-89de-d26e91df08d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-02-27T10:54:20.806324Z",
     "iopub.status.busy": "2025-02-27T10:54:20.805325Z",
     "iopub.status.idle": "2025-02-27T10:54:23.752107Z",
     "shell.execute_reply": "2025-02-27T10:54:23.752107Z",
     "shell.execute_reply.started": "2025-02-27T10:54:20.806324Z"
    },
    "executionInfo": {
     "elapsed": 182255,
     "status": "ok",
     "timestamp": 1713172919139,
     "user": {
      "displayName": "ff ff",
      "userId": "03856258937076952853"
     },
     "user_tz": -120
    },
    "id": "f4c669f6-7198-4ae1-8553-f2d7894f7a7c",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "656d80b9-ac91-4648-c33a-46b9f2b9b13e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Floor0\n",
      "Floor1\n",
      "Floor2\n",
      "Floor3\n",
      "Floor4\n",
      "Floor5\n",
      "Floor6\n",
      "Floor7\n",
      "Floor8\n",
      "Floor9\n"
     ]
    }
   ],
   "source": [
    "dataframes = fetch_dataset(\"./heterog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3479e7ce-9945-4a74-b3c2-565ff1609265",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T10:54:23.752107Z",
     "iopub.status.busy": "2025-02-27T10:54:23.752107Z",
     "iopub.status.idle": "2025-02-27T10:54:23.765721Z",
     "shell.execute_reply": "2025-02-27T10:54:23.763482Z",
     "shell.execute_reply.started": "2025-02-27T10:54:23.752107Z"
    },
    "id": "1cdbefe5-d379-4b86-aa22-6aaa8b882c4e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_clients = len(dataframes) #total number of clients to partition data into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5bfa2c4-4ab7-4431-b219-1b199e3275d7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-02-27T10:54:23.767740Z",
     "iopub.status.busy": "2025-02-27T10:54:23.767740Z",
     "iopub.status.idle": "2025-02-27T10:54:23.788819Z",
     "shell.execute_reply": "2025-02-27T10:54:23.786711Z",
     "shell.execute_reply.started": "2025-02-27T10:54:23.767740Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1713172919139,
     "user": {
      "displayName": "ff ff",
      "userId": "03856258937076952853"
     },
     "user_tz": -120
    },
    "id": "0d773663-a9bc-47c2-b9f7-1c9349f533fb",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "d0a2cbf5-eae0-4f85-e331-8677be637c4a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['total_demand', 'AC', 'Light', 'Plug', 'Year', 'Month', 'Day', 'Hour',\n",
      "       'Minute'],\n",
      "      dtype='object')\n",
      "(68183, 9)\n",
      "Index(['total_demand', 'AC', 'Light', 'Plug', 'Year', 'Month', 'Day', 'Hour',\n",
      "       'Minute'],\n",
      "      dtype='object')\n",
      "(58618, 9)\n",
      "Index(['total_demand', 'AC', 'Light', 'Plug', 'Year', 'Month', 'Day', 'Hour',\n",
      "       'Minute'],\n",
      "      dtype='object')\n",
      "(61943, 9)\n",
      "Index(['total_demand', 'AC', 'Light', 'Plug', 'Year', 'Month', 'Day', 'Hour',\n",
      "       'Minute'],\n",
      "      dtype='object')\n",
      "(50086, 9)\n",
      "Index(['total_demand', 'AC', 'Light', 'Plug', 'Year', 'Month', 'Day', 'Hour',\n",
      "       'Minute'],\n",
      "      dtype='object')\n",
      "(52978, 9)\n",
      "Index(['total_demand', 'AC', 'Light', 'Plug', 'Year', 'Month', 'Day', 'Hour',\n",
      "       'Minute'],\n",
      "      dtype='object')\n",
      "(47634, 9)\n",
      "Index(['total_demand', 'AC', 'Light', 'Plug', 'Year', 'Month', 'Day', 'Hour',\n",
      "       'Minute'],\n",
      "      dtype='object')\n",
      "(60309, 9)\n",
      "Index(['total_demand', 'AC', 'Light', 'Plug', 'Year', 'Month', 'Day', 'Hour',\n",
      "       'Minute'],\n",
      "      dtype='object')\n",
      "(67424, 9)\n",
      "Index(['total_demand', 'AC', 'Light', 'Plug', 'Year', 'Month', 'Day', 'Hour',\n",
      "       'Minute'],\n",
      "      dtype='object')\n",
      "(58210, 9)\n",
      "Index(['total_demand', 'AC', 'Light', 'Plug', 'Year', 'Month', 'Day', 'Hour',\n",
      "       'Minute'],\n",
      "      dtype='object')\n",
      "(62302, 9)\n"
     ]
    }
   ],
   "source": [
    "for _, df in dataframes.items():\n",
    "    print(df.columns)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aca677-485c-4c3c-a770-3d166c21fe5d",
   "metadata": {
    "id": "c7574d60-ad30-4735-b8f6-4d4fe1f6bee6"
   },
   "source": [
    "# Build the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50eb9f2e-6408-421a-b147-d4b6c5e662eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-02-27T10:54:23.794201Z",
     "iopub.status.busy": "2025-02-27T10:54:23.792961Z",
     "iopub.status.idle": "2025-02-27T10:54:31.130062Z",
     "shell.execute_reply": "2025-02-27T10:54:31.130062Z",
     "shell.execute_reply.started": "2025-02-27T10:54:23.793800Z"
    },
    "executionInfo": {
     "elapsed": 72570,
     "status": "ok",
     "timestamp": 1713172991707,
     "user": {
      "displayName": "ff ff",
      "userId": "03856258937076952853"
     },
     "user_tz": -120
    },
    "id": "c7ec2dc2-848d-4316-8f30-77b89866bd5c",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "fed71713-f93d-43e0-f667-bbf2f8779c59",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68093, 90, 9) (68093, 1)\n",
      "(58528, 90, 9) (58528, 1)\n",
      "(61853, 90, 9) (61853, 1)\n",
      "(49996, 90, 9) (49996, 1)\n",
      "(52888, 90, 9) (52888, 1)\n",
      "(47544, 90, 9) (47544, 1)\n",
      "(60219, 90, 9) (60219, 1)\n",
      "(67334, 90, 9) (67334, 1)\n",
      "(58120, 90, 9) (58120, 1)\n",
      "(62212, 90, 9) (62212, 1)\n"
     ]
    }
   ],
   "source": [
    "train_loader = []\n",
    "test_loader = []\n",
    "label_scalers = []\n",
    "for _, df in dataframes.items():\n",
    "    inputs_cols_indices = range(0, df.shape[1])  # use (total_demand,Year,Month,Day,Hour,Minute) columns as features\n",
    "    #move the window\n",
    "    inputs, labels = move_sliding_window(\n",
    "        df.values,\n",
    "        window_size,\n",
    "        inputs_cols_indices=inputs_cols_indices,\n",
    "        label_col_index=label_col_index\n",
    "    )\n",
    "\n",
    "    # Normalize the input data columns\n",
    "    sc = MinMaxScaler()\n",
    "    # Obtaining the scaler for the labels(usage data) so that output can be re-scaled to actual value during evaluation\n",
    "    label_sc = MinMaxScaler()\n",
    "\n",
    "    # Split data into train/test portions and combining all data into a single array\n",
    "    test_portion = int(0.2 * len(inputs))\n",
    "\n",
    "    train_x = sc.fit_transform(inputs[:-test_portion].reshape(-1, window_size * df.shape[1]))\n",
    "    train_x = train_x.reshape(-1, window_size, df.shape[1])\n",
    "    train_y = label_sc.fit_transform(labels[:-test_portion])\n",
    "\n",
    "    test_x = sc.transform(inputs[-test_portion:].reshape(-1, window_size * df.shape[1]))\n",
    "    test_x = test_x.reshape(-1, window_size, df.shape[1])\n",
    "    test_y = label_sc.transform(labels[-test_portion:])\n",
    "\n",
    "    # test_x.append(testx)\n",
    "    # test_y.append(testy)\n",
    "    label_scalers.append(label_sc)\n",
    "\n",
    "    # pytorch data loaders\n",
    "    train_data = TensorDataset(torch.from_numpy(train_x).to('cpu'), torch.from_numpy(train_y).to('cpu'))\n",
    "    train_loader.append(DataLoader(train_data, batch_size=batch_size, drop_last=True))# Drop the last incomplete batch\n",
    "    test_data = TensorDataset(torch.from_numpy(test_x).to('cpu'), torch.from_numpy(test_y).to('cpu'))\n",
    "    test_loader.append(DataLoader(test_data, batch_size=batch_size))# Drop the last incomplete batch\n",
    "\n",
    "    # release some memory\n",
    "    del train_x, train_y\n",
    "input_dim = next(iter(train_loader[0]))[0].shape[2]  # 22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b461da31-9566-4157-b161-22b0a4d50fc1",
   "metadata": {
    "id": "2ca3a158-c53d-4e1a-a73c-fe2c2dc7b458"
   },
   "source": [
    "# LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "684dcae9-ce88-492d-8c06-b454de18e8b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-02-27T10:54:31.132063Z",
     "iopub.status.busy": "2025-02-27T10:54:31.132063Z",
     "iopub.status.idle": "2025-02-27T10:54:31.172903Z",
     "shell.execute_reply": "2025-02-27T10:54:31.172903Z",
     "shell.execute_reply.started": "2025-02-27T10:54:31.132063Z"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1713172991707,
     "user": {
      "displayName": "ff ff",
      "userId": "03856258937076952853"
     },
     "user_tz": -120
    },
    "id": "47d095c5-331b-4ae9-8b8d-570ab5a4fa3d",
    "outputId": "d88777a9-bb84-4d7e-8474-d56d70197479",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMModel(\n",
      "  (lstm): LSTM(9, 50, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (tanh): Tanh()\n",
      ")\n",
      "32651\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTMModel(input_dim, hidden_dim, output_dim, n_layers)\n",
    "model_type = 'LSTM'\n",
    "print(lstm)\n",
    "print(num_params(lstm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd4bd71-78fb-476b-9142-2b1b41ca5a2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5e5fa12-22e8-4ad7-bacc-2c8617917d1e",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-02-27T10:54:31.174966Z",
     "iopub.status.busy": "2025-02-27T10:54:31.174966Z",
     "iopub.status.idle": "2025-02-27T10:58:54.908921Z",
     "shell.execute_reply": "2025-02-27T10:58:54.908522Z",
     "shell.execute_reply.started": "2025-02-27T10:54:31.174966Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "starting avg round 0\n",
      "clients:  [0 1 2 3 4 5 6 7 8 9]\n",
      "round 0, starting client 1/10, id: 0\n",
      "Epoch [1/1], Train Loss: 0.08848579147092575\n",
      "round 0, starting client 2/10, id: 1\n",
      "Epoch [1/1], Train Loss: 0.07827427296174898\n",
      "round 0, starting client 3/10, id: 2\n",
      "Epoch [1/1], Train Loss: 0.04822544027895978\n",
      "round 0, starting client 4/10, id: 3\n",
      "Epoch [1/1], Train Loss: 0.04887921210282887\n",
      "round 0, starting client 5/10, id: 4\n",
      "Epoch [1/1], Train Loss: 0.07544878465918507\n",
      "round 0, starting client 6/10, id: 5\n",
      "Epoch [1/1], Train Loss: 0.08722994411112489\n",
      "round 0, starting client 7/10, id: 6\n",
      "Epoch [1/1], Train Loss: 0.06851211507269675\n",
      "round 0, starting client 8/10, id: 7\n",
      "Epoch [1/1], Train Loss: 0.06518652053693165\n",
      "round 0, starting client 9/10, id: 8\n",
      "Epoch [1/1], Train Loss: 0.07374147607220548\n",
      "round 0, starting client 10/10, id: 9\n",
      "Epoch [1/1], Train Loss: 0.07390090316766873\n",
      "calc smape: 52.677583735408966%\n",
      "MAE: 11.480547639248444\n",
      "RMSE: 21.74877491235681\n",
      "Average Loss:  0.05401921451424303\n",
      "CPU times: total: 26min 16s\n",
      "Wall time: 4min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lstm_K5_kd = copy.deepcopy(lstm)\n",
    "outputs_kd1, targets_kd1, loss_kd1, smape_kd1, mae_kd1, rmse_kd1,global_model, aggregated_logits = fedavg(\n",
    "    global_model = lstm_K5_kd,\n",
    "    client_train_loader = train_loader,\n",
    "    test_loader = test_loader,\n",
    "    label_sc = label_scalers,\n",
    "    n_clients = n_clients,\n",
    "    batch_size = batch_size,\n",
    "    num_local_epochs = num_local_epochs,\n",
    "    lr = lr,\n",
    "    max_rounds = 1,\n",
    "    model_type = model_type,\n",
    "    device = device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edc6b7ba-0a31-4ff3-8f83-229a5c95c1ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T10:58:54.910927Z",
     "iopub.status.busy": "2025-02-27T10:58:54.909929Z",
     "iopub.status.idle": "2025-02-27T10:58:54.959762Z",
     "shell.execute_reply": "2025-02-27T10:58:54.959762Z",
     "shell.execute_reply.started": "2025-02-27T10:58:54.910927Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f9af21-1ca3-4c10-b3d4-d81a2116db91",
   "metadata": {
    "id": "J8W4MvgvhHEP",
    "tags": []
   },
   "source": [
    "## Fedwkd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfa3b9e4-1d05-4360-afde-dda36412a072",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T11:31:12.417288Z",
     "iopub.status.busy": "2025-02-27T11:31:12.417288Z",
     "iopub.status.idle": "2025-02-27T11:35:26.252549Z",
     "shell.execute_reply": "2025-02-27T11:35:26.251577Z",
     "shell.execute_reply.started": "2025-02-27T11:31:12.417288Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "starting round 1\n",
      "clients:  [0 1 2 3 4 5 6 7 8 9]\n",
      "round 1, starting client 1/10, id: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\fed\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1024, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Train Loss: 0.05076660194768095\n",
      "round 1, starting client 2/10, id: 1\n",
      "Epoch [1/1], Train Loss: 0.042104214284982955\n",
      "round 1, starting client 3/10, id: 2\n",
      "Epoch [1/1], Train Loss: 0.02757573638033742\n",
      "round 1, starting client 4/10, id: 3\n",
      "Epoch [1/1], Train Loss: 0.029804467104184322\n",
      "round 1, starting client 5/10, id: 4\n",
      "Epoch [1/1], Train Loss: 0.041686405541329866\n",
      "round 1, starting client 6/10, id: 5\n",
      "Epoch [1/1], Train Loss: 0.046375913746856345\n",
      "round 1, starting client 7/10, id: 6\n",
      "Epoch [1/1], Train Loss: 0.038671707457050356\n",
      "round 1, starting client 8/10, id: 7\n",
      "Epoch [1/1], Train Loss: 0.03790610799422631\n",
      "round 1, starting client 9/10, id: 8\n",
      "Epoch [1/1], Train Loss: 0.03906973163700766\n",
      "round 1, starting client 10/10, id: 9\n",
      "Epoch [1/1], Train Loss: 0.040465107536874725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\fed\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [0 0 0 0 0 0 0 0 0 0]\n",
      "calc smape: 58.102842248629436%\n",
      "MAE: 13.316796416257846\n",
      "RMSE: 17.60489989085443\n",
      "Average Loss:  0.036277582307633796\n",
      "peak memory: 4804.77 MiB, increment: 344.13 MiB\n"
     ]
    }
   ],
   "source": [
    "# Measure memory consumption\n",
    "%memit -r 1 fedkd(global_model = global_model,aggregated_logits=aggregated_logits,client_train_loader = train_loader,test_loader = test_loader,label_sc = label_scalers,n_clients = n_clients,batch_size = batch_size,num_local_epochs = num_local_epochs,lr = lr,max_rounds = 2,model_type = model_type,device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8746aa8-abc3-4dd6-8408-c589d8ab2e8f",
   "metadata": {},
   "source": [
    "## fedgkd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9620fe72-d245-4690-9f7d-7e3fb5a94d9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T11:42:28.253974Z",
     "iopub.status.busy": "2025-02-27T11:42:28.252974Z",
     "iopub.status.idle": "2025-02-27T11:42:28.269096Z",
     "shell.execute_reply": "2025-02-27T11:42:28.268096Z",
     "shell.execute_reply.started": "2025-02-27T11:42:28.253974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lstm_K5_gkd = copy.deepcopy(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "461e744f-1eab-48b7-b29e-543b345cc848",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T12:22:17.966850Z",
     "iopub.status.busy": "2025-02-27T12:22:17.966850Z",
     "iopub.status.idle": "2025-02-27T12:28:43.072316Z",
     "shell.execute_reply": "2025-02-27T12:28:43.071912Z",
     "shell.execute_reply.started": "2025-02-27T12:22:17.966850Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting round 0\n",
      "clients:  [0 1 2 3 4 5 6 7 8 9]\n",
      "round 0, starting client 1/10, id: 0\n",
      "Epoch [1/1], Train Loss: 0.014653398435703428\n",
      "round 0, starting client 2/10, id: 1\n",
      "Epoch [1/1], Train Loss: 0.012889184316413272\n",
      "round 0, starting client 3/10, id: 2\n",
      "Epoch [1/1], Train Loss: 0.01369987951572208\n",
      "round 0, starting client 4/10, id: 3\n",
      "Epoch [1/1], Train Loss: 0.017477316363977317\n",
      "round 0, starting client 5/10, id: 4\n",
      "Epoch [1/1], Train Loss: 0.012879181233030267\n",
      "round 0, starting client 6/10, id: 5\n",
      "Epoch [1/1], Train Loss: 0.013338164086579469\n",
      "round 0, starting client 7/10, id: 6\n",
      "Epoch [1/1], Train Loss: 0.014372283275774184\n",
      "round 0, starting client 8/10, id: 7\n",
      "Epoch [1/1], Train Loss: 0.015437479507034786\n",
      "round 0, starting client 9/10, id: 8\n",
      "Epoch [1/1], Train Loss: 0.01161098595087727\n",
      "round 0, starting client 10/10, id: 9\n",
      "Epoch [1/1], Train Loss: 0.013291690488889191\n",
      "calc smape: 42.84222619820313%\n",
      "MAE: 6.891559890380983\n",
      "RMSE: 11.93367708297831\n",
      "Average Loss:  0.01720941612216088\n",
      "peak memory: 4831.19 MiB, increment: 124.65 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit -r 1 fedgkd(global_model = lstm_K5_gkd,client_train_loader = train_loader,test_loader = test_loader,label_sc = label_scalers,n_clients = n_clients,batch_size = batch_size,num_local_epochs = num_local_epochs,lr = lr,max_rounds = 1,model_type = model_type,device = device,buffer_size=buffer_size,kd_weight=kd_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4837e39-b0df-46d9-af28-0fe34a9b02da",
   "metadata": {},
   "source": [
    "## cadis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e50d0a7-3aec-42ab-afdf-5e5a3b5a4eea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T12:28:43.074322Z",
     "iopub.status.busy": "2025-02-27T12:28:43.073324Z",
     "iopub.status.idle": "2025-02-27T12:28:43.088431Z",
     "shell.execute_reply": "2025-02-27T12:28:43.087430Z",
     "shell.execute_reply.started": "2025-02-27T12:28:43.074322Z"
    }
   },
   "outputs": [],
   "source": [
    "lstm_K5_cadis = copy.deepcopy(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7f7564e-3ef6-4507-8426-29f7831d60a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T12:28:43.090430Z",
     "iopub.status.busy": "2025-02-27T12:28:43.090430Z",
     "iopub.status.idle": "2025-02-27T12:36:07.049673Z",
     "shell.execute_reply": "2025-02-27T12:36:07.049673Z",
     "shell.execute_reply.started": "2025-02-27T12:28:43.090430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "starting round 0\n",
      "clients:  [0 1 2 3 4 5 6 7 8 9]\n",
      "round 0, starting client 1/10, id: 0\n",
      "Epoch [1/1], Loss: 4.6897\n",
      "round 0, starting client 2/10, id: 1\n",
      "Epoch [1/1], Loss: 3.5223\n",
      "round 0, starting client 3/10, id: 2\n",
      "Epoch [1/1], Loss: 2.3148\n",
      "round 0, starting client 4/10, id: 3\n",
      "Epoch [1/1], Loss: 1.9063\n",
      "round 0, starting client 5/10, id: 4\n",
      "Epoch [1/1], Loss: 3.0934\n",
      "round 0, starting client 6/10, id: 5\n",
      "Epoch [1/1], Loss: 3.2275\n",
      "round 0, starting client 7/10, id: 6\n",
      "Epoch [1/1], Loss: 3.2201\n",
      "round 0, starting client 8/10, id: 7\n",
      "Epoch [1/1], Loss: 3.3897\n",
      "round 0, starting client 9/10, id: 8\n",
      "Epoch [1/1], Loss: 3.3184\n",
      "round 0, starting client 10/10, id: 9\n",
      "Epoch [1/1], Loss: 3.5472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Desktop\\fedwkd\\util.py:152: ClusterWarning: scipy.cluster: The symmetric non-negative hollow observation matrix looks suspiciously like an uncondensed distance matrix\n",
      "  linkage_matrix = linkage(q_matrix, method='average')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calc smape: 52.76065109079408%\n",
      "MAE: 11.473552011533435\n",
      "RMSE: 21.65611635112987\n",
      "Average Loss:  0.05356896809089421\n",
      "peak memory: 5103.39 MiB, increment: 613.57 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit -r 1 cadis(global_model = lstm_K5_cadis,client_train_loader = train_loader,test_loader = test_loader,lambda_kd = 1,label_sc = label_scalers,n_clients = n_clients,batch_size = batch_size,num_local_epochs = num_local_epochs,lr = lr,max_rounds = max_rounds,model_type = model_type,device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad173395-b18d-4d97-af85-5c2371b4251b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "fed",
   "language": "python",
   "name": "fed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
